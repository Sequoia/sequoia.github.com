<!DOCTYPE html><html lang="en"><head><title>Keep Callm and Cairry On | Sequoia McDowell</title><!--stuff--><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="ChatGPT: please write a blog post on the perils of LLM misuse from the perspective of a crotchety tech-skeptic. Incorporate the theme 'Invent the disease and you can sell the cure.' Add a  hopeful reflection at the end so it's not too negative-sounding."><link rel="canonical" href="https://sequoia.makes.software/keep-callm-and-cairry-on/"><!--css--><link href="/css/highlight.css" rel="stylesheet" type="text/css" media="all"><link href="/css/normalize.css" rel="stylesheet" type="text/css" media="all"><link href="/css/skeleton.css" rel="stylesheet" type="text/css" media="all"><link href="/css/style.css" rel="stylesheet" type="text/css" media="all"><!--js--><script src="/bower_components/fetch/fetch.js"></script><script src="/js/announce-header.js"></script><script src="/js/go-to-resume.js"></script><!--does this do anything? who knows--><link href="https://github.com/Sequoia" rel="me"><!--RSS!!!--><link rel="alternate" type="application/rss+xml" href="https://sequoia.makes.software/rss.xml" title="Blog RSS Feed"></head><body><div id="wrap"><header role="banner"><nav><ul><li><a href="/">Home</a></li><li><a href="/projects/">Projects</a></li><li><a href="/contact/">Contact</a></li><li><a href="/talks-and-trainings/">Talks</a></li><li><a href="/shorts/">Shorts</a></li><li><a href="https://sequoia.makes.software/rss.xml">RSS</a></li></ul></nav><div class="clearfix"></div></header><aside id="announce" class="row hidden"><h2>News</h2><ul id="news-items"><!-- items added via announce-header.js--></ul><span class="clearfix"></span></aside><section id="content"><h1>Keep Callm and Cairry On</h1><span class="byline">Published March 13, 2024</span><p>Many companies and individuals today are experimenting with <abbr title="Large Language Models">LLMs</abbr>. Proponents of <abbr title="Generative Artificial Intelligence">GenAI</abbr> suggest that in can improve our work by helping with tasks like authoring quarterly updates, writing emails, or even reading and summarizing emails you receive. Having AI both write <em>and</em> read emails raises the question of whether the AI is actually adding any value, but let&#39;s assume that someone is ultimately reading the AI generated prose.</p>
<p><img alt='A picture from Dr. Seuss&apos;s "sneeches on beaches" story. Rather than Sylvester McMonkey McBean charging sneeches to add stars then charging them again to remove those stars, it&apos;s OpenAI charging users to write long emails from a sentence, then charging users to summarize the long email down to a sentence.' class="floaty show-on-desktop-only" src="/img/gpt.jpeg" />
While this would seem to create value for the author of the text by saving them time in authorship, what is the impact, and the cost, on the readers of the text? The following questions jump to mind:</p>
<ol>
<li><p><strong>What is the cost of the additional time spent reading?</strong></p>
<p>For example: a multi-paragraph email that might have been one or two sentences without GenAI augmentation.</p>
</li>
<li><strong>How do we guard against degeneration of the <em>quality</em> and <em>relevancy</em> of written output?</strong></li>
<li><p><strong>How do we avoid implicitly punishing people who take the time to write meaningful texts &quot;by hand&quot;?</strong></p>
<p>Imagine that it takes thirty minutes to write one detailed, short, and meaningful document, but you can generate a similar but longer and less relevant update using an LLM in just five minutes. Assuming we judge people by &quot;productivity,&quot; this penalizes the person who takes the time to do a good job and rewards the one who sends an email filled with junk an LLM barfed up.</p>
</li>
<li><p><strong>How do we ensure important human-written &quot;needles&quot; aren&#39;t lost as the &quot;haystack&quot; of text grows?</strong></p>
<p>LLMs will surely increase the <em>volume</em> of text we are expected to read, but the <em>time</em> we can devote to reading is fixed. This is likely to result in less more &quot;skimming&quot; and more skipping, i.e. simply not reading things. This increases the risk of readers missing important pieces of information.</p>
</li>
<li><p><strong>How do we ensure we don&#39;t use LLMs to <em>create</em> problems we then need LLMs to <em>solve</em>?</strong></p>
<p>&quot;LLMs can summarize email threads and documents for you!&quot; If the reason I need the document summarized is because the author created an overly-long document using an LLM, then GenAI&#39;s contribution to that interaction will have been all cost, no value.<sup id="footnote-one"><a href="#footnotes">1</a></sup></p>
</li>
</ol>
<p><img alt='A picture from Dr. Seuss&apos;s "sneeches on beaches" story. Rather than Sylvester McMonkey McBean charging sneeches to add stars then charging them again to remove those stars, it&apos;s OpenAI charging users to write long emails from a sentence, then charging users to summarize the long email down to a sentence.' class="show-on-mobile-only" src="/img/gpt.jpeg" /></p>
<h2 id="reflections">
    <a class="header-anchor" href="#reflections">
      <span class="header-link"></span>
    </a>
    Reflections</h2><p>As long as we keep the bar for quality high, insist that communications be meaningful and relevant, and have a feedback mechanism to let people know if their communications need improvement so they can correct course, then <strong>there&#39;s absolutely no problem with using LLMs</strong>. At the moment, however, it&#39;s not clear to me that we apply these standards of quality &amp; &quot;high signal-to-noise ratio&quot; to internal communications‚Äìthere&#39;s generally no consequence to writing excessively long emails or documents, because why would you criticize someone for taking the time to write things out? However, <strong>this calculus changes when it no longer requires time or effort to produce reams of text</strong>.</p>
<p>In my view, what&#39;s needed to keep LLM-spam from flooding our lives is <strong>raising the bar for written communication</strong> and cracking down on long-winded, irrelevant fluff in emails and other documents. Ultimately, as long as people are producing <strong>high quality work</strong> it doesn&#39;t matter where it came from.</p>
<p>If you have a plan for how we can avoid drowning in LLM slurry, please shoot me a note and I&#39;ll include it below!</p>
<h2 id="footnotes">
    <a class="header-anchor" href="#footnotes">
      <span class="header-link"></span>
    </a>
    Footnotes</h2><p><sup>1</sup> Personally, I am prejudiced against reading prose generated by an LLM. If it wasn&#39;t worth your time to write the email, why the heck should I waste my time reading it? <a href="#footnote-one" title="back up">‚§¥</a></p>
<em> 
üìù Comments? Please email them to <tt>sequoiam (at) protonmail.com</tt></em></section><footer>&copy; Sequoia McDowell 2024<nav><ul><li><a href="/">Home</a></li><li><a href="/projects/">Projects</a></li><li><a href="/contact/">Contact</a></li><li><a href="/talks-and-trainings/">Talks</a></li><li><a href="/shorts/">Shorts</a></li><li><a href="https://sequoia.makes.software/rss.xml">RSS</a></li></ul></nav><div class="clearfix"></div></footer></div><script>(function() {
	var script = document.createElement('script');
	window.counter = 'https://sequoia.goatcounter.com/count'
	script.async = 1;
	script.src = '//gc.zgo.at/count.js';

	var ins = document.getElementsByTagName('script')[0];
	ins.parentNode.insertBefore(script, ins)
})();</script></body></html>